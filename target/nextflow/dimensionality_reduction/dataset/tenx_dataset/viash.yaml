functionality:
  name: "tenx_dataset"
  namespace: "dimensionality_reduction/dataset"
  version: "dev"
  authors:
  - name: "Robrecht Cannoodt"
    email: "RCannoo1@its.jnj.com"
    roles:
    - "maintainer"
    props:
      account: "rcannoo1"
  arguments:
  - type: "string"
    name: "--input"
    alternatives:
    - "-i"
    description: "Location URL to an h5 file from the 10x genomics website."
    required: true
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--output"
    alternatives:
    - "-o"
    description: "Output h5 file."
    default: "${VIASH_PAR_INPUT##*/}"
    must_exist: false
    required: false
    direction: "Output"
    multiple: false
    multiple_sep: ":"
  resources:
  - type: "bash_script"
    text: |
      #!/usr/bin/env bash
      
      ##########################
      #    tenx_dataset dev    #
      ##########################
      
      # This wrapper script is auto-generated by viash 0.4.0-rc1 and is thus a
      # derivative work thereof. This software comes with ABSOLUTELY NO WARRANTY from
      # Data Intuitive.  The component may contain files which fall under a different
      # license. The authors of this component should specify the license in the
      # header of such files, or include a separate license file detailing the
      # licenses of all included files.
      #
      # Component authors:
      # * Robrecht Cannoodt <RCannoo1@its.jnj.com> (maintainer) {account: rcannoo1}
      
      set -e
      
      if [ -z "$VIASH_TEMP" ]; then
        VIASH_TEMP=/tmp
      fi
      
      # define helper functions
      # ViashQuote: put quotes around non flag values
      # $1     : unquoted string
      # return : possibly quoted string
      # examples:
      #   ViashQuote --foo      # returns --foo
      #   ViashQuote bar        # returns 'bar'
      #   Viashquote --foo=bar  # returns --foo='bar'
      function ViashQuote {
        if [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+=.+$ ]]; then
          echo "$1" | sed "s#=\(.*\)#='\1'#"
        elif [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+$ ]]; then
          echo "$1"
        else
          echo "'$1'"
        fi
      }
      # ViashRemoveFlags: Remove leading flag
      # $1     : string with a possible leading flag
      # return : string without possible leading flag
      # examples:
      #   ViashRemoveFlags --foo=bar  # returns bar
      function ViashRemoveFlags {
        echo "$1" | sed 's/^--*[a-zA-Z0-9_\-]*=//'
      }
      # ViashSourceDir: return the path of a bash file, following symlinks
      # usage   : ViashSourceDir ${BASH_SOURCE[0]}
      # $1      : Should always be set to ${BASH_SOURCE[0]}
      # returns : The absolute path of the bash file
      function ViashSourceDir {
        SOURCE="$1"
        while [ -h "$SOURCE" ]; do
          DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"
          SOURCE="$(readlink "$SOURCE")"
          [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
        done
        cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd
      }
      
      # find source folder of this component
      VIASH_RESOURCES_DIR=`ViashSourceDir ${BASH_SOURCE[0]}`
      VIASH_EXEC_MODE="run"
      
      function ViashSetup {
      :
      }
      
      
      # ViashHelp: Display helpful explanation about this executable
      function ViashHelp {
         echo "Download a dataset from the 10x genomics website.
      
      Example:
        fetch_10x_dataset \\
          --input https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5 \\
          --min_library_size 1000 --min_cells_per_gene 300"
         echo
         echo "Options:"
          echo "    -i string, --input=string"
          echo "        type: string, required parameter"
          echo "        Location URL to an h5 file from the 10x genomics website."
          echo ""
          echo "    -o file, --output=file"
          echo "        type: file, default: ${VIASH_PAR_INPUT##*/}"
          echo "        Output h5 file."
          echo ""
      }
      
      # initialise array
      VIASH_POSITIONAL_ARGS=''
      
      while [[ $# -gt 0 ]]; do
          case "$1" in
              -h|--help)
                  ViashHelp
                  exit;;
              ---setup)
                  VIASH_EXEC_MODE="setup"
                  shift 1
                  ;;
              ---push)
                  VIASH_EXEC_MODE="push"
                  shift 1
                  ;;
              --input)
                  VIASH_PAR_INPUT="$2"
                  shift 2
                  ;;
              --input=*)
                  VIASH_PAR_INPUT=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              -i)
                  VIASH_PAR_INPUT="$2"
                  shift 2
                  ;;
              --output)
                  VIASH_PAR_OUTPUT="$2"
                  shift 2
                  ;;
              --output=*)
                  VIASH_PAR_OUTPUT=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              -o)
                  VIASH_PAR_OUTPUT="$2"
                  shift 2
                  ;;
              *)  # positional arg or unknown option
                  # since the positional args will be eval'd, can we always quote, instead of using ViashQuote
                  VIASH_POSITIONAL_ARGS="$VIASH_POSITIONAL_ARGS '$1'"
                  shift # past argument
                  ;;
          esac
      done
      
      if [ "$VIASH_EXEC_MODE" == "setup" ]; then
        ViashSetup
        exit 0
      fi
      
      if [ "$VIASH_EXEC_MODE" == "push" ]; then
        ViashPush
        exit 0
      fi
      
      # parse positional parameters
      eval set -- $VIASH_POSITIONAL_ARGS
      
      
      
      # check whether required parameters exist
      if [ -z "$VIASH_PAR_INPUT" ]; then
        echo '--input' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z "$VIASH_PAR_OUTPUT" ]; then
        VIASH_PAR_OUTPUT="${VIASH_PAR_INPUT##*/}"
      fi
      
      
      cat << VIASHEOF | bash
      set -e
      tempscript=\$(mktemp "$VIASH_TEMP/viash-run-tenx_dataset-XXXXXX")
      function clean_up {
        rm "\$tempscript"
      }
      trap clean_up EXIT
      cat > "\$tempscript" << 'VIASHMAIN'
      # The following code has been auto-generated by Viash.
      par <- list(
        "input" = $( if [ ! -z ${VIASH_PAR_INPUT+x} ]; then echo "'$VIASH_PAR_INPUT'"; else echo NULL; fi ),
        "output" = $( if [ ! -z ${VIASH_PAR_OUTPUT+x} ]; then echo "'$VIASH_PAR_OUTPUT'"; else echo NULL; fi )
      )
      
      resources_dir = "$VIASH_RESOURCES_DIR"
      
      cat("Loading dependencies\\n")
      requireNamespace("reticulate", quietly = TRUE)
      reticulate::py_module_available("scanpy")
      library(anndata)
      
      ## VIASH START
      ## VIASH END
      
      cat("Downloading file from '", par\$input, "'\\n", sep = "")
      h5_tmp <- tempfile()
      on.exit({file.remove(h5_tmp)})
      download.file(par\$input, destfile = h5_tmp, quiet = TRUE)
      
      cat("Converting to h5ad\\n")
      sc <- reticulate::import("scanpy")
      
      adata <- sc\$read_10x_h5(h5_tmp)
      
      adata\$write_h5ad(par\$output, compression = "gzip")
      VIASHMAIN
      PATH="$VIASH_RESOURCES_DIR:\$PATH"
      
      Rscript "\$tempscript"
      
      VIASHEOF
      

    dest: "tenx_dataset"
    is_executable: true
  - type: "file"
    text: |
        docker.enabled = true
        docker.runOptions = "-i -v ${baseDir}:${baseDir}"
        process.container = "dataintuitive/portash"
        params {
          tenx_dataset__input = "value_not_found"
          tenx_dataset__output = "${VIASH_PAR_INPUT##*/}"
          id = ""
          input = ""
          output = ""
          testScript = "run_test.R"
          testResources = [ "test/run_test.R" ]
          tenx_dataset {
            name = "tenx_dataset"
            container = "dimensionality_reduction/dataset/tenx_dataset"
            containerTag = "dev"
            containerRegistry = ""
            command = "tenx_dataset"
            tests {
              isDefined = true
              testScript = "run_test.R"
              testResources = [ "test/run_test.R" ]
            }
            extensions {
              out = "${VIASH_PAR_INPUT##*/}"
            }
            arguments {
              input {
                name = "input"
                otype = "--"
                required = true
                type = "string"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                description = "Location URL to an h5 file from the 10x genomics website."
              }
              output {
                name = "output"
                otype = "--"
                required = false
                type = "file"
                direction = "Output"
                multiple = false
                multiple_sep = ":"
                description = "Output h5 file."
                value = "${params.tenx_dataset__output}"
              }
            }
          }
        }

    dest: "nextflow.config"
  - type: "file"
    text: |
      nextflow.preview.dsl=2
      import java.nio.file.Paths
      
      def renderCLI(command, arguments) {
      
          def argumentsList = arguments.collect{ it ->
              (it.otype == "")
                  ? "\'" + it.value + "\'"
                  : (it.type == "boolean_true")
                      ? it.otype + it.name
                      : (it.value == "")
                          ? ""
                          : it.otype + it.name + " \'" + ((it.value in List && it.multiple) ? it.value.join(it.multiple_sep): it.value) + "\'"
          }
      
          def command_line = command + argumentsList
      
          return command_line.join(" ")
      }
      
      def effectiveContainer(processParams) {
          def _registry = params.containsKey("containerRegistry") ? params.containerRegistry : processParams.containerRegistry
          def _name = processParams.container
          def _tag = params.containsKey("containerTag") ? params.containerTag : processParams.containerTag
      
          return (_registry == "" ? "" : _registry + "/") + _name + ":" + _tag
      }
      
      // files is either String, List[String] or HashMap[String,String]
      def outFromIn(files) {
          if (files in List || files in HashMap) {
              // We're in join mode, files is List[String]
              return "tenx_dataset" + "." + "${VIASH_PAR_INPUT##*/}"
          } else {
              // files filename is just a String
              def splitString = files.split(/\./)
              def prefix = splitString.head()
              def extension = splitString.last()
              return prefix + "." + "tenx_dataset" + "." + "${VIASH_PAR_INPUT##*/}"
          }
      }
      
      // In: Hashmap key -> DataObjects
      // Out: Arrays of DataObjects
      def overrideInput(params, str) {
      
          // `str` in fact can be one of:
          // - `String`,
          // - `List[String]`,
          // - `Map[String, String | List[String]]`
          // Please refer to the docs for more info
          def overrideArgs = params.arguments.collect{ it ->
            (it.value.direction == "Input" && it.value.type == "file")
              ? (str in List || str in HashMap)
                  ? (str in List)
                      ? it.value + [ "value" : str.join(it.value.multiple_sep)]
                      : (str[it.value.name] != null)
                          ? (str[it.value.name] in List)
                              ? it.value + [ "value" : str[it.value.name].join(it.value.multiple_sep)]
                              : it.value + [ "value" : str[it.value.name]]
                          : it.value
                  : it.value + [ "value" : str ]
              : it.value
          }
      
          def newParams = params + [ "arguments" : overrideArgs ]
      
          return newParams
      }
      
      def overrideOutput(params, str) {
      
          def update = [ "value" : str ]
      
          def overrideArgs = params.arguments.collect{it ->
            (it.direction == "Output" && it.type == "file")
              ? it + update
              : it
          }
      
          def newParams = params + [ "arguments" : overrideArgs ]
      
          return newParams
      }
      
      
      process tenx_dataset_process {
        
        tag "${id}"
        echo { (params.debug == true) ? true : false }
        cache 'deep'
        stageInMode "symlink"
        container "${container}"
        
        input:
          tuple val(id), path(input), val(output), val(container), val(cli)
        output:
          tuple val("${id}"), path("${output}")
        script:
          if (params.test)
              """
              # Some useful stuff
              export NUMBA_CACHE_DIR=/tmp/numba-cache
              # Running the pre-hook when necessary
              echo Nothing before
              # Adding NXF's `$moduleDir` to the path in order to resolve our own wrappers
              export PATH="./:${moduleDir}:\$PATH"
              ./${params.tenx_dataset.tests.testScript} | tee $output
              """
          else
              """
              # Some useful stuff
              export NUMBA_CACHE_DIR=/tmp/numba-cache
              # Running the pre-hook when necessary
              echo Nothing before
              # Adding NXF's `$moduleDir` to the path in order to resolve our own wrappers
              export PATH="${moduleDir}:\$PATH"
              $cli
              """
      }
      
      workflow tenx_dataset {
      
          take:
          id_input_params_
      
          main:
      
          def key = "tenx_dataset"
      
          def id_input_output_function_cli_ =
              id_input_params_.map{ id, input, _params ->
                  // TODO: make sure input is List[Path], HashMap[String,Path] or Path, otherwise convert
                  // NXF knows how to deal with an List[Path], not with HashMap !
                  def checkedInput =
                      (input in HashMap)
                          ? input.collect{ k, v -> v }.flatten()
                          : input
                  // filename is either String, List[String] or HashMap[String, String]
                  def filename =
                      (input in List || input in HashMap)
                          ? (input in List)
                              ? input.collect{ it.name }
                              : input.collectEntries{ k, v -> [ k, (v in List) ? v.collect{it.name} : v.name ] }
                          : input.name
                  def defaultParams = params[key] ? params[key] : [:]
                  def overrideParams = _params[key] ? _params[key] : [:]
                  def updtParams = defaultParams + overrideParams
                  // now, switch to arrays instead of hashes...
                  def outputFilename = (!params.test) ? outFromIn(filename) : updtParams.output
                  def updtParams1 = overrideInput(updtParams, filename)
                  def updtParams2 = overrideOutput(updtParams1, outputFilename)
                  new Tuple5(
                      id,
                      checkedInput,
                      outputFilename,
                      effectiveContainer(updtParams2),
                      renderCLI([updtParams2.command], updtParams2.arguments)
                  )
              }
          result_ = tenx_dataset_process(id_input_output_function_cli_) \
              | join(id_input_params_) \
              | map{ id, output, input, original_params ->
                  new Tuple3(id, output, original_params)
              }
      
          emit:
          result_
      
      }
      
      workflow {
      
         def id = params.id
         def ch_ = Channel.fromPath(params.input).map{ s -> new Tuple3(id, s, params)}
      
         tenx_dataset(ch_)
      }
      
      workflow test {
      
         take:
         rootDir
      
         main:
         params.test = true
         params.tenx_dataset.output = "tenx_dataset.log"
      
         Channel.from(rootDir) \
              | filter { params.tenx_dataset.tests.isDefined } \
              | map{ p -> new Tuple3(
                          "tests",
                          params.tenx_dataset.tests.testResources.collect{ file( p + it ) },
                          params
                      )} \
              | tenx_dataset
      
          emit:
          tenx_dataset.out
      }

    dest: "main.nf"
  description: "Download a dataset from the 10x genomics website.\n\nExample:\n  fetch_10x_dataset\
    \ \\\n    --input https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\
    \ \\\n    --min_library_size 1000 --min_cells_per_gene 300\n"
  tests:
  - type: "r_script"
    path: "test/run_test.R"
    is_executable: true
platform:
  type: "nextflow"
  id: "nextflow"
platforms: []
info:
  config: "src/dimensionality_reduction/dataset/tenx_dataset/config.vsh.yaml"
  platform: "nextflow"
  output: "target/nextflow/dimensionality_reduction/dataset/tenx_dataset"
  executable: "target/nextflow/dimensionality_reduction/dataset/tenx_dataset/tenx_dataset"
  viash_version: "0.4.0-rc1"
  git_commit: "d9e9ac9c11d4a4bd76d6fa485a91517feafe6f03"
  git_remote: "git@github.com:rcannood/scop_viash_demo.git"
